{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/535szxKtxrPAVEe7zbCh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinay2k2/DataScienceToolBox/blob/main/StopWordsAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK"
      ],
      "metadata": {
        "id": "32CGVeQfqCj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVBMUIdqp3H6",
        "outputId": "9296a457-efaa-47b8-ee07-aa73dc5724c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords in NLTK are ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "Length of NLTK Stopwords are 179\n",
            "Original words: ['This', 'is', 'an', 'example', 'sentence', 'with', 'some', 'stopwords', '.']\n",
            "Filtered words (NLTK): ['example', 'sentence', 'stopwords', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(f\"Stopwords in NLTK are {stopwords.words('english')}\")\n",
        "print(f\"Length of NLTK Stopwords are {len(stopwords.words('english'))}\")\n",
        "# Example text\n",
        "text = \"This is an example sentence with some stopwords.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words_nltk = [word for word in words if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "# Print the result\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words (NLTK):\", filtered_words_nltk)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPACY"
      ],
      "metadata": {
        "id": "Pugaz2Agqahy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English NLP model from spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text\n",
        "text = \"This is an example sentence with some stopwords.\"\n",
        "\n",
        "print(f\"Stopwords in SPACY are {nlp.Defaults.stop_words}\")\n",
        "print(f\"Length of SPACY Stopwords are {len(nlp.Defaults.stop_words)}\")\n",
        "\n",
        "# Process the text using spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words_spacy = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "# Print the result\n",
        "print(\"Original words:\", [token.text for token in doc])\n",
        "print(\"Filtered words (spaCy):\", filtered_words_spacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDcr4NrUqeL-",
        "outputId": "8242722f-7668-43b7-c3d4-73dc16579ba5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords in SPACY are {'thence', 'did', 'twenty', 'side', 'when', 'something', 'again', 'seems', 'whole', 'about', 'very', 'eight', 'please', 'it', 'might', 'both', 'rather', 'beyond', 'those', 'anyway', '’ll', 'any', 'everyone', 'other', 'nowhere', 'which', 'they', 'seemed', 'by', 'eleven', 'been', 'others', 'via', 'mostly', 'using', 'as', 'will', 'due', 'in', 'besides', 'out', 'somewhere', 'n’t', 'no', 'throughout', 'somehow', 'alone', 'its', 'there', 'why', 'done', 'say', 'more', 'thereupon', 'here', 'hereupon', \"n't\", '’s', 're', 'should', 'twelve', 'such', 'of', 'were', 'less', 'she', 'formerly', 'sometime', 'on', 'bottom', 'except', 'former', 'my', 'where', 'i', 'whereupon', 'thereby', 'still', 'how', 'that', 'four', 'anyone', 'hereby', 'never', 'make', 'an', 'nine', 'me', 'n‘t', 'beside', 'whither', 'yourself', 'many', 'none', 'unless', 'anyhow', 'sixty', 'these', 'thus', 'ever', 'our', 'keep', 'even', 'name', 'six', 'without', '’d', 'together', 'you', 'may', 'seem', 'onto', 'full', 'same', '‘ve', 'the', 'among', 'myself', 'down', 'herself', 'after', 'around', 'therefore', 'part', '’m', 'several', 'just', 'top', 'not', 'whence', 'yet', 'whom', 'moreover', 'call', 'someone', 'hereafter', 'what', '’re', 'within', 'own', 'last', 'empty', 'anywhere', 'must', 'various', 'few', 'itself', 'elsewhere', 'although', 'afterwards', 'her', 'above', 'become', 'because', 'has', 'always', 'whereby', 'two', 'everywhere', 'fifty', 'quite', \"'d\", 'amongst', 'third', 'five', 'too', 'behind', 'thereafter', 'anything', 'doing', 'towards', 'much', 'or', 'mine', 'with', 'to', 'while', 'through', 'whatever', 'whose', 'whereas', 'yourselves', \"'m\", 'most', 'until', 'then', 'all', 'he', 'this', 'nobody', 'well', 'have', \"'ll\", 'first', 'is', 'do', 'now', 'latterly', 'noone', 'thru', 'was', 'hers', 'had', 'at', 'but', 'used', 'every', 'go', 'us', 'am', 'see', 'upon', 'hence', 'only', 'became', 'fifteen', 'least', 'across', 'nevertheless', 'give', 'and', 'whenever', 'each', 'perhaps', 'along', 'whereafter', 'ca', '‘m', 'whoever', 'cannot', 'between', 'their', 'put', 'are', 'back', 'who', 'does', 'nothing', 'almost', 'wherein', 'three', 'him', 'be', 'off', 'made', '‘ll', '‘s', 'next', 'herein', 'we', 'toward', '‘d', 'themselves', 'ten', 'can', 'nor', 'them', 'becoming', 'neither', \"'re\", 'get', \"'s\", '‘re', 'otherwise', 'if', 'front', 'serious', 'since', 'latter', 'becomes', 'under', 'hundred', 'himself', '’ve', 'either', 'really', 'often', 'being', 'another', 'your', 'else', 'his', 'up', 'show', 'take', 'for', 'from', 'beforehand', 'namely', \"'ve\", 'against', 'could', 'wherever', 'yours', 'forty', 'everything', 'so', 'amount', 'already', 'per', 'would', 'ourselves', 'once', 'though', 'a', 'whether', 'before', 'however', 'further', 'enough', 'move', 'sometimes', 'into', 'seeming', 'indeed', 'over', 'below', 'than', 'ours', 'therein', 'during', 'one', 'also', 'meanwhile', 'regarding', 'some'}\n",
            "Length of SPACY Stopwords are 326\n",
            "Original words: ['This', 'is', 'an', 'example', 'sentence', 'with', 'some', 'stopwords', '.']\n",
            "Filtered words (spaCy): ['example', 'sentence', 'stopwords', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextBlob"
      ],
      "metadata": {
        "id": "HXVyZBS4qvz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Example text\n",
        "text = \"This is an example sentence with some stopwords.\"\n",
        "\n",
        "\n",
        "print(f\"Stopwords in Textblob are {stopwords.words('english')}\")\n",
        "print(f\"Length of Textblob Stopwords are {len(stopwords.words('english'))}\")\n",
        "\n",
        "# Create a TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words_textblob = [word for word in blob.words if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "# Print the result\n",
        "print(\"Original words:\", blob.words)\n",
        "print(\"Filtered words (TextBlob):\", filtered_words_textblob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB36sj0Eq3MM",
        "outputId": "5dcd9388-ec9b-4671-e9b9-f50190c59522"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords in Textblob are ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "Length of Textblob Stopwords are 179\n",
            "Original words: ['This', 'is', 'an', 'example', 'sentence', 'with', 'some', 'stopwords']\n",
            "Filtered words (TextBlob): ['example', 'sentence', 'stopwords']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gensim"
      ],
      "metadata": {
        "id": "eaeyfZUYrFLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "# Example text\n",
        "text = \"This is an example sentence with some stopwords.\"\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Stopwords in Gensim are {STOPWORDS}\")\n",
        "print(f\"Length of Gensim Stopwords are {len(STOPWORDS)}\")\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = text.split()\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words_gensim = [word for word in words if word.lower() not in STOPWORDS]\n",
        "\n",
        "# Print the result\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words (Gensim):\", filtered_words_gensim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiK9LMvirHEr",
        "outputId": "5b7b89b7-3df5-4b63-89e8-97b288f0367a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords in Gensim are frozenset({'thence', 'did', 'twenty', 'side', 'when', 'something', 'seems', 'again', 'whole', 'about', 'very', 'eight', 'please', 'ie', 'it', 'might', 'both', 'rather', 'beyond', 'those', 'anyway', 'any', 'didn', 'everyone', 'other', 'find', 'nowhere', 'which', 'they', 'seemed', 'by', 'eleven', 'been', 'others', 'via', 'mostly', 'using', 'co', 'as', 'will', 'due', 'in', 'besides', 'out', 'bill', 'somewhere', 'no', 'throughout', 'somehow', 'alone', 'its', 'there', 'why', 'done', 'say', 'more', 'thereupon', 'interest', 'here', 'hereupon', 're', 'should', 'twelve', 'such', 'of', 'doesn', 'were', 'less', 'inc', 'she', 'formerly', 'sometime', 'con', 'on', 'bottom', 'except', 'former', 'my', 'where', 'i', 'whereupon', 'thereby', 'still', 'how', 'that', 'four', 'anyone', 'hereby', 'never', 'make', 'an', 'nine', 'me', 'beside', 'whither', 'yourself', 'many', 'kg', 'none', 'unless', 'anyhow', 'sixty', 'these', 'thus', 'ever', 'our', 'keep', 'even', 'name', 'six', 'without', 'together', 'you', 'may', 'seem', 'onto', 'full', 'same', 'the', 'among', 'myself', 'down', 'herself', 'after', 'eg', 'around', 'therefore', 'part', 'several', 'just', 'top', 'not', 'whence', 'computer', 'yet', 'whom', 'moreover', 'mill', 'call', 'someone', 'hereafter', 'what', 'within', 'own', 'last', 'empty', 'anywhere', 'must', 'various', 'few', 'itself', 'elsewhere', 'although', 'afterwards', 'her', 'above', 'become', 'because', 'has', 'always', 'found', 'whereby', 'two', 'everywhere', 'fifty', 'quite', 'amongst', 'third', 'too', 'five', 'behind', 'thereafter', 'anything', 'doing', 'towards', 'much', 'or', 'mine', 'with', 'un', 'to', 'while', 'through', 'whatever', 'whose', 'whereas', 'yourselves', 'thin', 'most', 'ltd', 'until', 'then', 'all', 'he', 'this', 'etc', 'nobody', 'well', 'have', 'first', 'is', 'do', 'now', 'latterly', 'noone', 'thru', 'was', 'hers', 'had', 'fill', 'at', 'but', 'used', 'every', 'go', 'us', 'am', 'see', 'sincere', 'upon', 'hence', 'only', 'became', 'fifteen', 'least', 'across', 'nevertheless', 'give', 'and', 'whenever', 'each', 'perhaps', 'along', 'whereafter', 'whoever', 'de', 'cannot', 'km', 'between', 'their', 'put', 'are', 'couldnt', 'back', 'who', 'does', 'nothing', 'describe', 'almost', 'wherein', 'three', 'him', 'be', 'off', 'made', 'amoungst', 'next', 'herein', 'we', 'toward', 'fire', 'themselves', 'ten', 'can', 'nor', 'them', 'neither', 'becoming', 'get', 'otherwise', 'if', 'front', 'system', 'serious', 'since', 'latter', 'becomes', 'under', 'hundred', 'himself', 'either', 'really', 'often', 'being', 'thick', 'another', 'your', 'else', 'his', 'up', 'show', 'take', 'for', 'from', 'beforehand', 'cant', 'namely', 'against', 'could', 'wherever', 'yours', 'forty', 'everything', 'so', 'amount', 'already', 'per', 'would', 'ourselves', 'once', 'though', 'whether', 'a', 'before', 'however', 'further', 'detail', 'enough', 'move', 'hasnt', 'sometimes', 'into', 'seeming', 'cry', 'indeed', 'don', 'over', 'below', 'than', 'ours', 'therein', 'during', 'one', 'also', 'meanwhile', 'regarding', 'some'})\n",
            "Length of Gensim Stopwords are 337\n",
            "Original words: ['This', 'is', 'an', 'example', 'sentence', 'with', 'some', 'stopwords.']\n",
            "Filtered words (Gensim): ['example', 'sentence', 'stopwords.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKLEARN\n"
      ],
      "metadata": {
        "id": "d4NXW-4NrTwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "# Example text\n",
        "text = \"This is an example sentence with some stopwords.\"\n",
        "\n",
        "\n",
        "print(f\"Stopwords in sklearn are {ENGLISH_STOP_WORDS}\")\n",
        "print(f\"Length of sklearn Stopwords are {len(ENGLISH_STOP_WORDS)}\")\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = text.split()\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words_sklearn = [word for word in words if word.lower() not in ENGLISH_STOP_WORDS]\n",
        "\n",
        "# Print the result\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words (scikit-learn):\", filtered_words_sklearn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1IU9e6KrTc1",
        "outputId": "254a85ed-b811-4f85-9eec-436c013fd1a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords in sklearn are frozenset({'thence', 'twenty', 'side', 'when', 'something', 'again', 'seems', 'whole', 'about', 'very', 'eight', 'please', 'ie', 'it', 'might', 'both', 'rather', 'beyond', 'those', 'anyway', 'any', 'everyone', 'other', 'find', 'nowhere', 'which', 'they', 'seemed', 'by', 'eleven', 'been', 'others', 'via', 'mostly', 'co', 'as', 'will', 'due', 'in', 'besides', 'out', 'bill', 'somewhere', 'no', 'throughout', 'somehow', 'alone', 'its', 'there', 'why', 'done', 'more', 'thereupon', 'interest', 'here', 'hereupon', 're', 'should', 'twelve', 'such', 'of', 'were', 'less', 'inc', 'she', 'formerly', 'sometime', 'con', 'on', 'bottom', 'except', 'former', 'my', 'where', 'i', 'whereupon', 'thereby', 'still', 'how', 'that', 'four', 'anyone', 'hereby', 'never', 'an', 'nine', 'me', 'beside', 'whither', 'yourself', 'many', 'none', 'anyhow', 'sixty', 'these', 'thus', 'ever', 'our', 'keep', 'even', 'name', 'six', 'without', 'together', 'you', 'may', 'seem', 'onto', 'full', 'same', 'the', 'among', 'myself', 'down', 'herself', 'after', 'eg', 'around', 'therefore', 'part', 'several', 'top', 'not', 'whence', 'yet', 'whom', 'moreover', 'mill', 'call', 'someone', 'hereafter', 'what', 'within', 'own', 'last', 'empty', 'anywhere', 'must', 'few', 'itself', 'elsewhere', 'although', 'afterwards', 'her', 'above', 'become', 'because', 'has', 'always', 'found', 'whereby', 'two', 'everywhere', 'fifty', 'amongst', 'third', 'five', 'too', 'behind', 'thereafter', 'anything', 'towards', 'much', 'or', 'mine', 'with', 'un', 'to', 'while', 'through', 'whatever', 'whose', 'whereas', 'yourselves', 'thin', 'most', 'ltd', 'until', 'then', 'all', 'he', 'this', 'etc', 'nobody', 'well', 'have', 'first', 'is', 'do', 'now', 'latterly', 'noone', 'thru', 'was', 'hers', 'had', 'fill', 'at', 'but', 'every', 'go', 'us', 'am', 'see', 'sincere', 'upon', 'hence', 'only', 'became', 'fifteen', 'least', 'across', 'nevertheless', 'give', 'and', 'whenever', 'each', 'perhaps', 'along', 'whereafter', 'whoever', 'de', 'cannot', 'between', 'their', 'put', 'are', 'couldnt', 'back', 'who', 'nothing', 'describe', 'almost', 'wherein', 'three', 'him', 'be', 'off', 'made', 'amoungst', 'next', 'herein', 'we', 'toward', 'fire', 'themselves', 'ten', 'can', 'nor', 'them', 'becoming', 'neither', 'get', 'otherwise', 'if', 'front', 'system', 'serious', 'since', 'latter', 'becomes', 'under', 'hundred', 'himself', 'either', 'often', 'being', 'thick', 'another', 'your', 'else', 'his', 'up', 'show', 'take', 'for', 'from', 'beforehand', 'cant', 'namely', 'against', 'could', 'wherever', 'yours', 'forty', 'everything', 'so', 'amount', 'already', 'per', 'would', 'ourselves', 'once', 'though', 'a', 'whether', 'before', 'however', 'further', 'detail', 'enough', 'move', 'hasnt', 'sometimes', 'into', 'seeming', 'cry', 'indeed', 'over', 'below', 'than', 'ours', 'therein', 'during', 'one', 'also', 'meanwhile', 'some'})\n",
            "Length of sklearn Stopwords are 318\n",
            "Original words: ['This', 'is', 'an', 'example', 'sentence', 'with', 'some', 'stopwords.']\n",
            "Filtered words (scikit-learn): ['example', 'sentence', 'stopwords.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow and PyTorch, as deep learning frameworks, do not inherently provide predefined stopword lists like some NLP-specific libraries (e.g., NLTK, spaCy, TextBlob). However, you can still leverage stopwords from other libraries or define your own list of stopwords when working with text data in the context of these frameworks."
      ],
      "metadata": {
        "id": "34cTHdk5r05F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using NLTK with TensorFlow:\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example text\n",
        "text = \"This is an example sentence with some stopwords.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords using NLTK\n",
        "filtered_words_nltk = [word for word in words if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "# Convert to TensorFlow tensor\n",
        "tensor_text = tf.constant(filtered_words_nltk)\n",
        "\n",
        "# Print the result\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words (NLTK with TensorFlow):\", tensor_text.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJSy1SjQr3hn",
        "outputId": "33b4530c-470c-447f-ea74-4f5b4ddcc037"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original words: ['This', 'is', 'an', 'example', 'sentence', 'with', 'some', 'stopwords', '.']\n",
            "Filtered words (NLTK with TensorFlow): [b'example' b'sentence' b'stopwords' b'.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}